{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program 1                DATA AGGREGATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in dataframes from gzip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gz_to_df(name):\n",
    "    df=pd.DataFrame()\n",
    "    df = pd.read_csv(name,header=None,usecols=[1,3,11],parse_dates=[1])\n",
    "    cols = [\"DATE\",\"STORENUMBER\",\"SALES\"]\n",
    "    df.columns=cols\n",
    "    df = df.loc[:,['STORENUMBER','DATE','SALES']]\n",
    "    df.sort_values(by=['STORENUMBER','DATE'],inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate transactions by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_transactions_by_day(data):\n",
    "    data.sort_values(by=['DATE'],inplace=True)\n",
    "    #set datetime as index\n",
    "    data=data.set_index('DATE')\n",
    "    #resample and sum by day\n",
    "    data=data.resample('D').sum()\n",
    "    #restore date columns\n",
    "    data=data.reset_index()\n",
    "#    print('Aggregated One Dataframe')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate one dataframe at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_one_dataframe(df):  \n",
    "    df_agg=pd.DataFrame()\n",
    "    stores = df['STORENUMBER'].unique()\n",
    "    for store in stores:\n",
    "        dfs = pd.DataFrame()\n",
    "        dfs = df[df['STORENUMBER'] == store]\n",
    "        dfs = dfs.drop(['STORENUMBER'],axis=1)\n",
    "        dfs = aggregate_transactions_by_day(dfs)\n",
    "        days = dfs.shape[0]\n",
    "        storenumber = [store for i in range(days)]\n",
    "        dfs['STORENUMBER'] = storenumber\n",
    "        df_agg = pd.concat([df_agg,dfs],axis=0,ignore_index=True)\n",
    "    df_agg = df_agg.loc[:,['STORENUMBER','DATE','SALES']]\n",
    "    df_agg.reset_index(drop=True,inplace=True)\n",
    "    return df_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read, aggregate and concatenate all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_data_files():\n",
    "    data = pd.DataFrame();df=pd.DataFrame()\n",
    "    fnames=os.listdir(os.getcwd()+'/SF_data')\n",
    "    for name in fnames:\n",
    "        name=os.getcwd() + '/SF_data/' + str(name)\n",
    "        if name.endswith('.gz'):\n",
    "            df = gz_to_df(name)\n",
    "            df = aggregate_one_dataframe(df)\n",
    "            print('Aggregated One DataFrame')\n",
    "            data = pd.concat([data,df],axis=0,ignore_index=True)\n",
    "        else: continue\n",
    "    data.to_feather('SF_data/SF_daily_data.feather')\n",
    "    print('Data Stored To agg_data/daily_data.feather')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Aggregated One DataFrame\n",
      "Data Stored To SF_data/SF_daily_data.feather\n"
     ]
    }
   ],
   "source": [
    "process_all_data_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLOSE AND HALT NOTEBOOK WHEN COMPLETED\n",
    "After execution of this notebook it should be 'close and halt\" under the File menu selection. This notebook perform so many caluculations tht it tends to corrupt memory locations.  Since the majority of the operations are in dataframe aggregation and mergers or in disk memory access multi-processing or GPU operations will not improve speed.  Distributed processing under DASK would work but required a cpu/gpu network and this is intended to operate on a single host for demonstration purposes.  'Close and halt' will start a cleaner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceed to Program 2:  SFFeatures.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
